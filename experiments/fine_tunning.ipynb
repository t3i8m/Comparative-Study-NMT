{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers==4.51.3 nltk evaluate tqdm bert_score wandb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WboIZeWB2ecX",
        "outputId": "aed25b0c-d3ca-4ac7-92f3-5e0817e7530f",
        "ExecuteTime": {
          "end_time": "2025-05-12T09:30:35.534029800Z",
          "start_time": "2025-05-12T09:29:53.409180700Z"
        }
      },
      "id": "WboIZeWB2ecX",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: transformers==4.51.3 in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.28.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c3849878",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3849878",
        "outputId": "157de341-cdbc-48d2-a3b5-d2184bb7ad41",
        "ExecuteTime": {
          "end_time": "2025-05-12T09:30:37.329572600Z",
          "start_time": "2025-05-12T09:30:35.530030Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"fine_tunning.ipynb\"), \"..\")))\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "import numpy as np\n",
        "# from transformers_models.marian.marianMT import\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED_VALUE = 42\n",
        "\n",
        "\n",
        "random.seed(SEED_VALUE)\n",
        "np.random.seed(SEED_VALUE)"
      ],
      "metadata": {
        "id": "Ogp2_jDE_KHY",
        "ExecuteTime": {
          "end_time": "2025-05-12T09:30:38.049188300Z",
          "start_time": "2025-05-12T09:30:37.343891500Z"
        }
      },
      "id": "Ogp2_jDE_KHY",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "#GETS SYNONYM FOR A WORD\n",
        "\n",
        "def get_synonym(word):\n",
        "    synonyms = wordnet.synsets(word)\n",
        "    if not synonyms:\n",
        "        return None\n",
        "\n",
        "    lemmas = synonyms[0].lemmas()\n",
        "    for lemma in lemmas:\n",
        "        synonym = lemma.name().replace(\"_\", \" \")\n",
        "        if synonym.lower() != word.lower():\n",
        "            return synonym\n",
        "    return None\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.351199200Z"
        },
        "id": "982663a69ab05109",
        "outputId": "6308aa02-b3ac-428c-ef7f-2d0fcf7ecfe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "982663a69ab05109",
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "#GETS THE NEIGHBORS OF A QWERTY KEYBOARD\n",
        "def build_qwerty_neighbors():\n",
        "    layout = [\n",
        "        \"qwertyuiop\",\n",
        "        \"asdfghjkl\",\n",
        "        \"zxcvbnm\"\n",
        "    ]\n",
        "    neighbors = {}\n",
        "\n",
        "    for row in layout:\n",
        "        for i, char in enumerate(row):\n",
        "            neighbor_chars = []\n",
        "            if i > 0:\n",
        "                neighbor_chars.append(row[i - 1])\n",
        "            if i < len(row) - 1:\n",
        "                neighbor_chars.append(row[i + 1])\n",
        "            neighbors[char] = ''.join(neighbor_chars)\n",
        "\n",
        "    return neighbors\n",
        "\n",
        "QWERTY_NEIGHBORS = build_qwerty_neighbors()\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.369473600Z"
        },
        "id": "d4014578028390f"
      },
      "id": "d4014578028390f",
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "#INTRODUCE TYPOS\n",
        "def typo_char(c):\n",
        "    if c.lower() in QWERTY_NEIGHBORS:\n",
        "        return random.choice(QWERTY_NEIGHBORS[c.lower()])\n",
        "    return c"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.378813500Z"
        },
        "id": "72547ae4bb6b4afa"
      },
      "id": "72547ae4bb6b4afa",
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "#CHOOSES IN 20% OF WORDS, ONE OF THE FOLLOWING NOISES\n",
        "def add_noise(text, noise_prob=0.2):\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if random.random() < noise_prob:\n",
        "            noise_type = random.choice([\"delete_word\", \"duplicate_word\", \"shuffle\", \"synonym\", \"char_noise\"])\n",
        "\n",
        "            if noise_type == \"delete_word\":\n",
        "                continue\n",
        "\n",
        "            elif noise_type == \"duplicate_word\":\n",
        "                noisy_words.extend([word, word])\n",
        "\n",
        "            elif noise_type == \"shuffle\":\n",
        "                if len(words) > 1:\n",
        "                    idx = words.index(word)\n",
        "                    if idx < len(words) - 1:\n",
        "                        noisy_words.append(words[idx + 1])\n",
        "                        noisy_words.append(word)\n",
        "                        continue\n",
        "\n",
        "            elif noise_type == \"synonym\":\n",
        "                cleaned_word = word.strip('.,?!')\n",
        "                synonym = get_synonym(cleaned_word.lower())\n",
        "                noisy_words.append(synonym if synonym else word)\n",
        "\n",
        "            elif noise_type == \"char_noise\":\n",
        "                noisy_word = \"\"\n",
        "                for char in word:\n",
        "                    if random.random() < 0.2:\n",
        "                        char_noise_type = random.choice([\"typo\", \"duplicate\", \"delete\", \"replace\"])\n",
        "                        if char_noise_type == \"typo\":\n",
        "                            noisy_word += typo_char(char)\n",
        "                        elif char_noise_type == \"duplicate\":\n",
        "                            noisy_word += char * 2\n",
        "                        elif char_noise_type == \"delete\":\n",
        "                            continue\n",
        "                        elif char_noise_type == \"replace\":\n",
        "                            noisy_word += random.choice(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "                    else:\n",
        "                        noisy_word += char\n",
        "                noisy_words.append(noisy_word)\n",
        "        else:\n",
        "            noisy_words.append(word)\n",
        "\n",
        "    return \" \".join(noisy_words)"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.390971200Z"
        },
        "id": "4caa7d77008f6f57"
      },
      "id": "4caa7d77008f6f57",
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_data(max_length=30, add_text_noise=False, noise_level=0.2):\n",
        "    dataset = load_dataset(\"wmt14\", \"de-en\")\n",
        "\n",
        "    raw_subset = dataset[\"train\"].select(range(200000))\n",
        "\n",
        "    def is_short(example):\n",
        "        return len(example[\"translation\"][\"de\"].split()) <= max_length and len(example[\"translation\"][\"en\"].split()) <= max_length\n",
        "\n",
        "    filtered = raw_subset.filter(is_short)\n",
        "\n",
        "    if add_text_noise:\n",
        "        def apply_noise(example):\n",
        "            example[\"translation\"][\"de\"] = add_noise(example[\"translation\"][\"de\"], noise_level)\n",
        "            example[\"translation\"][\"en\"] = add_noise(example[\"translation\"][\"en\"], noise_level)\n",
        "            return example\n",
        "\n",
        "        filtered = filtered.map(apply_noise)\n",
        "\n",
        "    train_data = filtered.select(range(50000))\n",
        "    val_data = filtered.select(range(50000, 53000))\n",
        "    test_data = filtered.select(range(53000, 56000))\n",
        "\n",
        "    return {\n",
        "        \"train\": train_data,\n",
        "        \"validation\": val_data,\n",
        "        \"test\": test_data\n",
        "    }"
      ],
      "metadata": {
        "id": "eLbXcHwiAXMT",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.401413Z"
        }
      },
      "id": "eLbXcHwiAXMT",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6b0062dd",
      "metadata": {
        "id": "6b0062dd",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.416389100Z"
        }
      },
      "outputs": [],
      "source": [
        "def translated(n, model):\n",
        "    return model.translate_text(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "97ba5951",
      "metadata": {
        "id": "97ba5951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "a8f22e94-8255-497e-8fe1-a69134fcf34e",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.439103400Z"
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid pattern: '**' can only be an entire path component",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0d6639b9b17c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-1bef6a1ba69c>\u001b[0m in \u001b[0;36mretrieve_data\u001b[0;34m(max_length, add_text_noise, noise_level)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mretrieve_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_text_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wmt14\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"de-en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mraw_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2113\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1799\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m                         \u001b[0;34mf\"Couldn't find '{path}' on the Hugging Face Hub either: {type(e1).__name__}: {e1}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m                     ) from None\n\u001b[0;32m-> 1495\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         raise FileNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m                     \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m                     \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m                 ).get_module()\n\u001b[0m\u001b[1;32m   1480\u001b[0m         except (\n\u001b[1;32m   1481\u001b[0m             \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m         data_files = DataFilesDict.from_patterns(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mget_data_patterns\u001b[0;34m(base_path, download_config)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolve_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_data_files_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEmptyDatasetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The directory at {base_path} doesn't contain any data files\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36m_get_data_files_patterns\u001b[0;34m(pattern_resolver)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                     \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_path_and_storage_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fs_token_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0mfs_base_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_marker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mfs_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/core.py\u001b[0m in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_expand_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expand_info\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detail\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     def find(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mallpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithdirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mends_with_sep\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/utils.py\u001b[0m in \u001b[0;36mglob_translate\u001b[0;34m(pat)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"**\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    732\u001b[0m                 \u001b[0;34m\"Invalid pattern: '**' can only be an entire path component\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid pattern: '**' can only be an entire path component"
          ]
        }
      ],
      "source": [
        "data = retrieve_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[\"train\"].shape)\n",
        "print(data[\"test\"].shape)\n",
        "print(data[\"validation\"].shape)"
      ],
      "metadata": {
        "id": "bGXS8tyE_dft",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.453736900Z"
        }
      },
      "id": "bGXS8tyE_dft",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15662f64",
      "metadata": {
        "id": "15662f64",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.468080600Z"
        }
      },
      "outputs": [],
      "source": [
        "data[\"validation\"][\"translation\"][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da2205f",
      "metadata": {
        "id": "2da2205f",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.481205500Z"
        }
      },
      "outputs": [],
      "source": [
        "data[\"test\"][\"translation\"][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0030a374",
      "metadata": {
        "id": "0030a374",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.498390600Z"
        }
      },
      "outputs": [],
      "source": [
        "data[\"train\"][\"translation\"][:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab8c124",
      "metadata": {
        "id": "7ab8c124",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.518808600Z"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be817daf",
      "metadata": {
        "id": "be817daf",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.537253700Z"
        }
      },
      "outputs": [],
      "source": [
        "english = [n[\"en\"] for n in data[\"train\"][\"translation\"]]\n",
        "german = [n[\"de\"] for n in data[\"train\"][\"translation\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dad41e94",
      "metadata": {
        "id": "dad41e94",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.550659800Z"
        }
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf9abf6",
      "metadata": {
        "id": "3cf9abf6",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.568358700Z"
        }
      },
      "outputs": [],
      "source": [
        "def preprocess(batch):\n",
        "    src_texts = [ex[\"en\"] for ex in batch[\"translation\"]]\n",
        "    tgt_texts = [ex[\"de\"] for ex in batch[\"translation\"]]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        src_texts,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=40\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            tgt_texts,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=40\n",
        "        )[\"input_ids\"]\n",
        "\n",
        "    labels = [\n",
        "        [(token if token != tokenizer.pad_token_id else -100) for token in seq]\n",
        "        for seq in labels\n",
        "    ]\n",
        "\n",
        "    model_inputs[\"labels\"] = labels\n",
        "    return model_inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bda10e4",
      "metadata": {
        "id": "7bda10e4",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.578600300Z"
        }
      },
      "outputs": [],
      "source": [
        "tokenized_data = {\n",
        "    \"train\": data[\"train\"].map(preprocess, batched = True),\n",
        "    \"validation\": data[\"validation\"].map(preprocess, batched=True)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcabd7ca",
      "metadata": {
        "id": "bcabd7ca",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.593919200Z"
        }
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "test_subset = data[\"test\"].select(range(3000))\n",
        "\n",
        "src_texts = [ex[\"translation\"][\"en\"] for ex in test_subset]\n",
        "references = [[ex[\"translation\"][\"de\"]] for ex in test_subset]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "batch_size = 16\n",
        "predictions = []\n",
        "\n",
        "for i in tqdm(range(0, len(src_texts), batch_size), desc=\"Translating\"):\n",
        "    batch = src_texts[i:i + batch_size]\n",
        "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=60)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, num_beams=4, max_length=60, early_stopping=True)\n",
        "    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "    predictions.extend(preds)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references[:10]"
      ],
      "metadata": {
        "id": "g8s2Z9YgCm10",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.610494300Z"
        }
      },
      "id": "g8s2Z9YgCm10",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[:10]\n"
      ],
      "metadata": {
        "id": "ndGIvUp6cgj8",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.620845700Z"
        }
      },
      "id": "ndGIvUp6cgj8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meteor = evaluate.load(\"meteor\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n"
      ],
      "metadata": {
        "id": "-sJseus2E8MZ",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.632445500Z"
        }
      },
      "id": "-sJseus2E8MZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = bleu.compute(predictions=predictions, references=references)\n",
        "meteor_score = meteor.compute(predictions=predictions, references=[r[0] for r in references])\n",
        "bert_score = bertscore.compute(predictions=predictions, references=[r[0] for r in references], lang=\"de\")\n"
      ],
      "metadata": {
        "id": "ayliFVHdGQPj",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.642582700Z"
        }
      },
      "id": "ayliFVHdGQPj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score_BEFORE = bleu_score\n",
        "meteor_score_BEFORE = meteor_score\n",
        "bert_score_BEFORE = bert_score"
      ],
      "metadata": {
        "id": "WB_INXJok3C8",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.653586300Z"
        }
      },
      "id": "WB_INXJok3C8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f0dfe3",
      "metadata": {
        "id": "27f0dfe3",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.669366100Z"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "print(f\"BLEU before fine-tunning score: {bleu_score['bleu']:.4f}\")\n",
        "\n",
        "print(\"METEOR:\", meteor_score[\"meteor\"])\n",
        "print(\"BERTScore:\")\n",
        "bert_precision = sum(bert_score['precision']) / len(bert_score['precision']) # TP/(TP+FP)\n",
        "bert_recall = sum(bert_score['recall']) / len(bert_score['recall']) # TP/(TP+FN)\n",
        "bert_f1 = sum(bert_score['f1']) / len(bert_score['f1'])\n",
        "print(f\"  Precision: {bert_precision:.4f}\")\n",
        "print(f\"  Recall:    {bert_recall:.4f}\")\n",
        "print(f\"  F1:        {bert_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Metric': ['BLEU', 'METEOR', 'Precision(BERT)', 'Recall(BERT)', 'F1(BERT)'],\n",
        "    'Score': [bleu_score['bleu'], meteor_score[\"meteor\"], bert_precision, bert_recall, bert_f1]\n",
        "})\n",
        "\n",
        "sns.set(style=\"white\", context=\"talk\")\n",
        "palette = sns.color_palette(\"viridis\", len(data))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(x='Metric', y='Score', data=data, palette=palette)\n",
        "\n",
        "for i, row in data.iterrows():\n",
        "    ax.text(i, row['Score'] + 0.025, f\"{row['Score']:.4f}\",\n",
        "            ha='center', va='bottom',  fontsize=12)\n",
        "\n",
        "plt.title(\"Evaluation Metrics Before Fine-Tuning\", fontsize=18, pad=20)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.ylabel(\"Score\", fontsize=14)\n",
        "plt.xlabel(\"\")\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "sns.despine()\n",
        "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
        "ax.set_axisbelow(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "D1jzV0OcG0gb",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.676606500Z"
        }
      },
      "id": "D1jzV0OcG0gb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "FLxQQHuG641c",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.686024700Z"
        }
      },
      "id": "FLxQQHuG641c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "bleu_metric = load(\"bleu\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    list_of_lists = [[lbl] for lbl in decoded_labels]\n",
        "    flat_list= decoded_labels\n",
        "\n",
        "\n",
        "\n",
        "    bleu = bleu_metric.compute(predictions=decoded_preds, references=list_of_lists)\n",
        "\n",
        "    meteor_score = meteor.compute(predictions=decoded_preds, references=list_of_lists)\n",
        "\n",
        "    bert_score = bertscore.compute(predictions=decoded_preds, references=flat_list, lang=\"de\")\n",
        "    bert_precision = sum(bert_score['precision']) / len(bert_score['precision']) # TP/(TP+FP)\n",
        "    bert_recall = sum(bert_score['recall']) / len(bert_score['recall']) # TP/(TP+FN)\n",
        "    bert_f1 = sum(bert_score['f1']) / len(bert_score['f1'])\n",
        "\n",
        "    return {\n",
        "        \"bleu\": bleu[\"bleu\"],\n",
        "        \"meteor\": meteor_score[\"meteor\"],\n",
        "        \"bertscore_precision\": bert_precision,\n",
        "        \"bertscore_recall\": bert_recall,\n",
        "        \"bertscore_f1\": bert_f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "98EY51_gN1bL",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.697493600Z"
        }
      },
      "id": "98EY51_gN1bL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n"
      ],
      "metadata": {
        "id": "_S5MyX5ZOjrf",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.704699700Z"
        }
      },
      "id": "_S5MyX5ZOjrf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "KelW6EvsOuvO",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.709813Z"
        }
      },
      "id": "KelW6EvsOuvO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.Seq2SeqTrainingArguments.__init__.__code__.co_varnames)\n",
        "\n"
      ],
      "metadata": {
        "id": "lp1w9yVOO7vO",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.715961400Z"
        }
      },
      "id": "lp1w9yVOO7vO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "f4NSqI6W7UYh",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.723316200Z"
        }
      },
      "id": "f4NSqI6W7UYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "617ce55f",
      "metadata": {
        "id": "617ce55f",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.736554900Z"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./marianmt-finetuned\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=7,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_total_limit=2,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=500,\n",
        "    load_best_model_at_end=True,\n",
        "    #metric_for_best_model=\"bleu\",\n",
        "    #greater_is_better=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d88f57d",
      "metadata": {
        "id": "9d88f57d",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.746732400Z"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "    compute_metrics=compute_metrics,\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "log_history   = trainer.state.log_history\n",
        "epoch_entries = [e for e in log_history if \"epoch\" in e]\n",
        "\n",
        "metrics = [\n",
        "    \"loss\",\n",
        "    \"learning_rate\",\n",
        "    \"eval_loss\",\n",
        "    \"eval_bleu\",\n",
        "    \"eval_meteor\",\n",
        "    \"eval_bertscore_precision\",\n",
        "    \"eval_bertscore_recall\",\n",
        "    \"eval_bertscore_f1\"\n",
        "]\n",
        "names = {\n",
        "    \"loss\": \"Training Loss\",\n",
        "    \"learning_rate\": \"Learning Rate\",\n",
        "    \"eval_loss\": \"Validation Loss\",\n",
        "    \"eval_bleu\": \"BLEU\",\n",
        "    \"eval_meteor\": \"METEOR\",\n",
        "    \"eval_bertscore_precision\": \"BERTScore Precision\",\n",
        "    \"eval_bertscore_recall\": \"BERTScore Recall\",\n",
        "    \"eval_bertscore_f1\": \"BERTScore F1\"\n",
        "}\n",
        "\n",
        "n = len(metrics)\n",
        "cols = 4\n",
        "rows = math.ceil(n / cols)\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3*rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "cmap = plt.get_cmap('tab10')\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    ax = axes[i]\n",
        "    currdata = [(e[\"epoch\"], e[metric]) for e in epoch_entries if metric in e]\n",
        "    if not currdata:\n",
        "        ax.set_visible(False)\n",
        "        continue\n",
        "    epochs, values = zip(*currdata)\n",
        "\n",
        "    ax.plot(epochs, values,\n",
        "            marker='o',\n",
        "            linestyle='-',\n",
        "            color=cmap(i % 10),\n",
        "            label=names.get(metric, metric))\n",
        "    ax.set_title(names.get(metric, metric), fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(names.get(metric, metric))\n",
        "    ax.grid(linestyle='--', alpha=0.5)\n",
        "\n",
        "for ax in axes[n:]:\n",
        "    ax.set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T5uJMLOc-d5n",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.754727800Z"
        }
      },
      "id": "T5uJMLOc-d5n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = retrieve_data()\n",
        "model = trainer.model\n",
        "tokenizer = trainer.tokenizer"
      ],
      "metadata": {
        "id": "8BGz5MBii4lf",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.760901800Z"
        }
      },
      "id": "8BGz5MBii4lf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"bleu\")\n",
        "test_subset = data[\"test\"].select(range(3000))\n",
        "\n",
        "src_texts = [ex[\"translation\"][\"en\"] for ex in test_subset]\n",
        "references = [[ex[\"translation\"][\"de\"]] for ex in test_subset]\n",
        "\n",
        "batch_size = 16\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "predictions = []\n",
        "\n",
        "for i in tqdm(range(0, len(src_texts), batch_size), desc=\"Translating\"):\n",
        "    batch = src_texts[i:i + batch_size]\n",
        "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=60)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=60, num_beams=4, early_stopping=True)\n",
        "    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    predictions.extend(preds)"
      ],
      "metadata": {
        "id": "o1qe9k399D3G",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.768097200Z"
        }
      },
      "id": "o1qe9k399D3G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "references[:10]"
      ],
      "metadata": {
        "id": "bHjml_N9avVo",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.774098800Z"
        }
      },
      "id": "bHjml_N9avVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[:10]"
      ],
      "metadata": {
        "id": "UEZ2J1xAay0G",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.786317800Z"
        }
      },
      "id": "UEZ2J1xAay0G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = bleu.compute(predictions=predictions, references=references)\n",
        "meteor_score = meteor.compute(predictions=predictions, references=[r[0] for r in references])\n",
        "bert_score = bertscore.compute(predictions=predictions, references=[r[0] for r in references], lang=\"de\")"
      ],
      "metadata": {
        "id": "-MScX_7mLSqx",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.793325900Z"
        }
      },
      "id": "-MScX_7mLSqx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score_AFTER = bleu_score\n",
        "meteor_score_AFTER = meteor_score\n",
        "bert_score_AFTER = bert_score"
      ],
      "metadata": {
        "id": "YRKJT6-Fk_fJ",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.802588200Z"
        }
      },
      "id": "YRKJT6-Fk_fJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_precision = sum(bert_score['precision']) / len(bert_score['precision']) # TP/(TP+FP)\n",
        "bert_recall = sum(bert_score['recall']) / len(bert_score['recall']) # TP/(TP+FN)\n",
        "bert_f1 = sum(bert_score['f1']) / len(bert_score['f1'])\n",
        "\n",
        "print(f\"BLEU:   {bleu_score['bleu']:.4f}\")\n",
        "print(f\"METEOR: {meteor_score['meteor']:.4f}\")\n",
        "print(\"BERTScore:\")\n",
        "print(f\"  Precision: {bert_precision:.4f}\")\n",
        "print(f\"  Recall:    {bert_recall:.4f}\")\n",
        "print(f\"  F1:        {bert_f1:.4f}\")"
      ],
      "metadata": {
        "id": "GndfEFNd9Xnh",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.812046800Z"
        }
      },
      "id": "GndfEFNd9Xnh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Metric': ['BLEU', 'METEOR', 'Precision(BERT)', 'Recall(BERT)', 'F1(BERT)'],\n",
        "    'Score': [bleu_score['bleu'], meteor_score[\"meteor\"], bert_precision, bert_recall, bert_f1]\n",
        "})\n",
        "\n",
        "sns.set(style=\"white\", context=\"talk\")\n",
        "palette = sns.color_palette(\"viridis\", len(data))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(x='Metric', y='Score', data=data, palette=palette)\n",
        "\n",
        "for i, row in data.iterrows():\n",
        "    ax.text(i, row['Score'] + 0.025, f\"{row['Score']:.4f}\",\n",
        "            ha='center', va='bottom',  fontsize=12)\n",
        "\n",
        "plt.title(\"Evaluation Metrics After Fine-Tuning\", fontsize=18, pad=20)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.ylabel(\"Score\", fontsize=14)\n",
        "plt.xlabel(\"\")\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "sns.despine()\n",
        "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
        "ax.set_axisbelow(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RRn31EsjLPhf",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.820450900Z"
        }
      },
      "id": "RRn31EsjLPhf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "bleu_before= bleu_score_BEFORE[\"bleu\"]\n",
        "meteor_before= meteor_score_BEFORE[\"meteor\"]\n",
        "prec_before= np.mean(bert_score_BEFORE[\"precision\"])\n",
        "rec_before= np.mean(bert_score_BEFORE[\"recall\"])\n",
        "f1_before= np.mean(bert_score_BEFORE[\"f1\"])\n",
        "\n",
        "bleu_after= bleu_score_AFTER[\"bleu\"]\n",
        "meteor_after= meteor_score_AFTER[\"meteor\"]\n",
        "prec_after= np.mean(bert_score_AFTER[\"precision\"])\n",
        "rec_after= np.mean(bert_score_AFTER[\"recall\"])\n",
        "f1_after= np.mean(bert_score_AFTER[\"f1\"])\n",
        "\n",
        "before = [bleu_before, meteor_before, prec_before, rec_before, f1_before]\n",
        "after  = [bleu_after,  meteor_after,  prec_after,  rec_after,  f1_after]\n",
        "metrics = [\n",
        "    \"BLEU\",\n",
        "    \"METEOR\",\n",
        "    \"BERTScore Precision\",\n",
        "    \"BERTScore Recall\",\n",
        "    \"BERTScore F1\"\n",
        "]\n",
        "\n",
        "rows, cols = 2, 3\n",
        "fig, axes = plt.subplots(\n",
        "    rows, cols,\n",
        "    figsize=(14, 8),\n",
        "    constrained_layout=True\n",
        ")\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, ax in enumerate(axes):\n",
        "    if idx < len(metrics):\n",
        "        vals = [before[idx], after[idx]]\n",
        "        ax.bar(\n",
        "            [\"Before\", \"After\"],\n",
        "            vals,\n",
        "            color=[\"orange\", \"green\"],\n",
        "            width=0.7\n",
        "        )\n",
        "        ax.set_title(metrics[idx], fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel(\"Score\")\n",
        "        ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "        top = max(vals) * 1.25\n",
        "        ax.set_ylim(0, top)\n",
        "\n",
        "        for i, v in enumerate(vals):\n",
        "            ax.text(\n",
        "                i, v + top * 0.02,\n",
        "                f\"{v:.3f}\",\n",
        "                ha='center',\n",
        "                va='bottom',\n",
        "                fontsize=10\n",
        "            )\n",
        "    else:\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6qgYT3flk9oj",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.827578400Z"
        }
      },
      "id": "6qgYT3flk9oj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1240251",
      "metadata": {
        "id": "a1240251",
        "ExecuteTime": {
          "start_time": "2025-05-12T09:30:37.836792200Z"
        }
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(\"marianmt-finetuned\")\n",
        "# tokenizer.save_pretrained(\"marianmt-finetuned\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}